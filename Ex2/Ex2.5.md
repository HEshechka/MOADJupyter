# Отчет по заданию: Анализ данных пассажиров "Титаника" и прогнозирование выживаемости

## 1. Введение и цель работы

Целью данной работы является проведение анализа данных о пассажирах парохода "Титаник" для выявления факторов, влияющих на выживаемость, и построение моделей машинного обучения для предсказания выживаемости пассажиров. Работа включает этапы загрузки и предварительного анализа данных, их предобработку, обучение нескольких моделей классификации (дерево решений, KNN, SVM, наивный Байес, логистическая регрессия), подбор гиперпараметров и оценку качества моделей.

## 2. Описание набора данных

Использовался набор данных `titanic.csv`, содержащий информацию о пассажирах "Титаника", включая следующие признаки:
* `PassengerId`: Уникальный идентификатор пассажира.
* `Survived`: Целевая переменная (0 = Погиб, 1 = Выжил).
* `Pclass`: Класс каюты (1, 2, 3).
* `Name`: Имя пассажира.
* `Sex`: Пол пассажира.
* `Age`: Возраст пассажира.
* `SibSp`: Количество братьев, сестер или супругов на борту.
* `Parch`: Количество родителей или детей на борту.
* `Ticket`: Номер билета.
* `Fare`: Стоимость билета.
* `Cabin`: Номер каюты.
* `Embarked`: Порт посадки (C = Cherbourg, Q = Queenstown, S = Southampton).

В ходе первичного анализа были выявлены пропущенные значения в столбцах `Age`, `Cabin` и `Embarked`.

## 3. Методология выполнения работы

### 3.1. Загрузка и предварительный анализ данных
Данные были загружены с использованием библиотеки pandas. Проведен первичный осмотр:
* Вывод первых строк датасета (`data.head()`).
* Получение общей информации о типах данных и наличии пропусков (`data.info()`).
* Расчет описательных статистик (`data.describe()`).
* Подсчет и визуализация пропущенных значений.

### 3.2. Разведочный анализ данных (EDA)
На этом этапе были исследованы зависимости между признаками и целевой переменной, а также даны ответы на поставленные аналитические вопросы:
* **Влияние класса каюты (`Pclass`)**: Установлено, что пассажиры 1-го класса имели наивысшие шансы на выживание, а 3-го – наименьшие.
* **Влияние пола (`Sex`)**: Женщины выживали значительно чаще мужчин (например, около 74% женщин против 19% мужчин).
* **Анализ возраста (`Age`)**: Определены минимальный, максимальный и средний возраст пассажиров. Анализ по возрастным группам (например, Дети, Молодые, Взрослые, Пожилые) показал, что дети имели более высокие шансы на выживание.
* **Анализ количества родственников (`SibSp`, `Parch`)**: Выявлено максимальное количество родственников на борту. Рассчитана доля пассажиров, путешествующих в одиночку (SibSp=0 и Parch=0), которая составила значительную часть. Небольшое количество родственников (1-3) коррелировало с более высокой выживаемостью.
* **Зависимость стоимости билета (`Fare`) от выживаемости**: Пассажиры с более дорогими билетами имели более высокие шансы на выживание.
* **Влияние порта посадки (`Embarked`)**: Пассажиры, севшие в Шербуре (C), имели более высокие шансы на выживание.

Для ответов на вопросы использовались группировки, агрегирующие функции и визуализации (гистограммы, столбчатые диаграммы, ящики с усами).

### 3.3. Предобработка данных
* **Удаление признаков**: Были удалены столбцы `PassengerId`, `Name`, `Ticket` и `Cabin` как неинформативные для базовых моделей или имеющие слишком много пропусков (`Cabin`). `AgeGroup`, созданный для EDA, также был удален перед моделированием.
* **Обработка пропущенных значений**:
    * `Age`: Пропуски заполнены медианным значением.
    * `Embarked`: Пропуски заполнены наиболее частым значением (модой).
* **Кодирование категориальных признаков**:
    * Признаки `Sex` и `Embarked` были преобразованы с использованием `LabelEncoder` в предоставленном ноутбуке. Для улучшения, рекомендуется использовать `OneHotEncoder` для номинальных признаков, включая `Pclass`, `Sex`, `Embarked`, что было реализовано в улучшенной версии скрипта.
* **Масштабирование числовых признаков**: Числовые признаки (`Age`, `Fare`, `SibSp`, `Parch`) рекомендуется масштабировать с помощью `StandardScaler` для моделей, чувствительных к масштабу (KNN, SVM, логистическая регрессия). Этот шаг был включен в улучшенный пайплайн.
* **Использование `Pipeline` и `ColumnTransformer`**: Для автоматизации и корректного применения шагов предобработки был создан конвейер, раздельно обрабатывающий числовые и категориальные признаки.

### 3.4. Разделение выборки
Данные были разделены на обучающую (70%) и тестовую (30%) выборки с использованием `train_test_split`. Для обеспечения репрезентативности выборок была применена стратификация по целевой переменной `Survived`.

### 3.5. Построение, обучение и оценка моделей

Для оценки качества моделей использовался набор метрик: Accuracy, Precision, Recall (полнота), F1-score, ROC AUC, Specificity (особенность) и Fall-out (FPR). Для каждой модели строились матрица несоответствий и ROC-кривая.

#### 3.5.1. Дерево решений
* Модель `DecisionTreeClassifier` была обучена на предобработанных данных.
* Проведен подбор оптимальных гиперпараметров (`criterion`, `max_depth`, `min_samples_split`, `min_samples_leaf`) с помощью `GridSearchCV`.
* Лучшая модель дерева решений была визуализирована для интерпретации правил классификации.

#### 3.5.2. Другие методы классификации
Были обучены и оценены следующие модели с подбором гиперпараметров через `GridSearchCV`:
* **Метод k-ближайших соседей (KNN)**: Подбирались `n_neighbors`, `weights`, `metric`.
* **Метод опорных векторов (SVM)**: Подбирались `C`, `gamma`, `kernel`. Использовался параметр `probability=True` для расчета ROC AUC.
* **Наивный байесовский классификатор (GaussianNB)**: Подбирался параметр `var_smoothing`.
* **Логистическая регрессия**: Подбирались `C`, `penalty`, `solver`.

## 4. Результаты и сравнение моделей

Все обученные модели были оценены на тестовой выборке. Результаты метрик были сведены в таблицу для сравнения.

--- Сводная таблица метрик для всех моделей (отсортировано по ROC AUC) ---

                              Accuracy  Precision    Recall        F1  \
K-ближайших соседей (KNN)     0.805970   0.800000  0.660194  0.723404   
Логистическая регрессия       0.798507   0.763441  0.689320  0.724490   
Гауссовский Наивный Байес     0.697761   0.823529  0.271845  0.408759   
Метод опорных векторов (SVM)  0.791045   0.747368  0.689320  0.717172   
Дерево решений (Лучшее)       0.794776   0.875000  0.543689  0.670659   

                               ROC_AUC  Specificity  Fall_out  
K-ближайших соседей (KNN)     0.851809     0.896970  0.103030  
Логистическая регрессия       0.849220     0.866667  0.133333  
Гауссовский Наивный Байес     0.847396     0.963636  0.036364  
Метод опорных векторов (SVM)  0.847396     0.854545  0.145455  
Дерево решений (Лучшее)       0.829509     0.951515  0.048485

**Выбор наилучшей модели:**
Основываясь на метриках производительности, особенно ROC AUC, логистическая регрессия и SVM (с ядром RBF) демонстрируют наиболее сильные результаты в задаче предсказания выживаемости пассажиров "Титаника". Эти модели обладают хорошей способностью различать классы. Важно отметить, что при выборе наилучшей модели необходимо учитывать баланс между различными метриками и контекст задачи. Дерево решений, несмотря на несколько более низкие значения ROC AUC, предлагает значительное преимущество в интерпретируемости, что может быть критичным в сценариях, где понимание логики принятия решений имеет первостепенное значение. Гауссовский Наивный Байес, хотя и является быстрым, может быть менее эффективным из-за предположения о независимости признаков. KNN, в свою очередь, требует тщательной настройки гиперпараметров и может быть менее эффективен по сравнению с другими методами в данном контексте. Для дальнейшего улучшения производительности можно рассмотреть возможность более глубокой оптимизации гиперпараметров, инженерии признаков или использования ансамблевых методов.

## 5. Выводы

В ходе работы был проведен всесторонний анализ данных пассажиров "Титаника", выявлены ключевые факторы, влияющие на выживаемость, и построены различные модели классификации.
* Наиболее значимыми факторами выживаемости оказались класс каюты, пол и возраст пассажира.
* Применение `Pipeline` и `ColumnTransformer` позволило корректно и эффективно провести предобработку данных.
* Подбор гиперпараметров с помощью `GridSearchCV` улучшил качество большинства моделей.
* Логистическая регрессия и SVM показали себя как наиболее точные модели для данной задачи на основании метрики ROC AUC.

Выбор конкретной модели для практического применения будет зависеть от приоритетов: если важна максимальная точность, то это могут быть Логистическая регрессия или SVM; если важна интерпретируемость – Дерево решений.

## 6. Используемые инструменты и библиотеки

* Python 3
* pandas – для загрузки и манипуляции данными.
* numpy – для численных операций.
* matplotlib и seaborn – для визуализации данных.
* scikit-learn – для построения и оценки моделей машинного обучения, предобработки данных и подбора гиперпараметров.
* Jupyter Notebook (или PyCharm с поддержкой .ipynb) – как среда для разработки.
